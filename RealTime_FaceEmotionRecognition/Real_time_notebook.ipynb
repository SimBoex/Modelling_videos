{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from time import sleep\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/simoneboesso/Desktop/Modelling_videos/RealTime_FaceEmotionRecognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"final_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[206 234 195]\n",
      "  [205 233 194]\n",
      "  [208 235 196]\n",
      "  ...\n",
      "  [ 96 101 119]\n",
      "  [105 111 128]\n",
      "  [118 124 141]]\n",
      "\n",
      " [[209 236 197]\n",
      "  [206 234 195]\n",
      "  [210 237 198]\n",
      "  ...\n",
      "  [ 90  96 113]\n",
      "  [102 107 125]\n",
      "  [109 114 132]]\n",
      "\n",
      " [[210 237 198]\n",
      "  [206 234 195]\n",
      "  [211 238 199]\n",
      "  ...\n",
      "  [ 90  93 111]\n",
      "  [ 99 102 120]\n",
      "  [110 113 130]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[202 199 143]\n",
      "  [203 200 144]\n",
      "  [203 200 146]\n",
      "  ...\n",
      "  [ 25  15  29]\n",
      "  [ 32  22  36]\n",
      "  [ 37  28  42]]\n",
      "\n",
      " [[201 198 141]\n",
      "  [201 198 141]\n",
      "  [202 199 144]\n",
      "  ...\n",
      "  [ 35  25  40]\n",
      "  [ 32  22  36]\n",
      "  [ 28  18  33]]\n",
      "\n",
      " [[201 198 141]\n",
      "  [201 198 141]\n",
      "  [202 199 144]\n",
      "  ...\n",
      "  [ 32  22  36]\n",
      "  [ 29  20  34]\n",
      "  [ 34  24  38]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/simoneboesso/anaconda3/envs/transformer/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/simoneboesso/anaconda3/envs/transformer/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/simoneboesso/anaconda3/envs/transformer/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/simoneboesso/anaconda3/envs/transformer/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"/Users/simoneboesso/anaconda3/envs/transformer/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/simoneboesso/anaconda3/envs/transformer/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model' (type Functional).\n    \n    Input 0 of layer \"Conv1\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 224, 224, 1)\n    \n    Call arguments received by layer 'model' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 224, 224, 1), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m roi\u001b[38;5;241m=\u001b[39mimg_to_array(roi)\n\u001b[1;32m     30\u001b[0m roi\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mexpand_dims(roi,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m#Expand dims to get it ready for prediction (1, 48, 48, 1)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m preds\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroi\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m#Yields one hot encoded result for 7 classes\u001b[39;00m\n\u001b[1;32m     33\u001b[0m label\u001b[38;5;241m=\u001b[39mclass_labels[preds\u001b[38;5;241m.\u001b[39margmax()]  \u001b[38;5;66;03m#Find the label\u001b[39;00m\n\u001b[1;32m     34\u001b[0m label_position\u001b[38;5;241m=\u001b[39m(x,y)\n",
      "File \u001b[0;32m~/anaconda3/envs/transformer/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/f7/gd5km_f51z3b_0fkjn895nt80000gn/T/__autograph_generated_file0eqwr2ts.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/simoneboesso/anaconda3/envs/transformer/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/simoneboesso/anaconda3/envs/transformer/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/simoneboesso/anaconda3/envs/transformer/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/simoneboesso/anaconda3/envs/transformer/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"/Users/simoneboesso/anaconda3/envs/transformer/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/simoneboesso/anaconda3/envs/transformer/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model' (type Functional).\n    \n    Input 0 of layer \"Conv1\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 224, 224, 1)\n    \n    Call arguments received by layer 'model' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 224, 224, 1), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.txt')\n",
    "\n",
    "class_labels=['Angry','Disgust', 'Fear', 'Happy','Neutral','Sad','Surprise']\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Main webcam is can't be opened\")\n",
    "    cap=cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open secondary Webcam\")\n",
    "    \n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read() # each frame is one image\n",
    "    print(frame)\n",
    "    \n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_cascade.detectMultiScale(gray,1.3,5)\n",
    "    if len(faces) == 0:\n",
    "        \"Face is not detected\"\n",
    "        \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray=gray[y:y+h,x:x+w]\n",
    "        roi_gray=cv2.resize(roi_gray,(224,224),interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "        #Get image ready for prediction\n",
    "        roi=roi_gray.astype('float')/255.0  #Scale\n",
    "        roi=img_to_array(roi)\n",
    "        roi=np.expand_dims(roi,axis=0)  #Expand dims to get it ready for prediction (1, 48, 48, 1)\n",
    "\n",
    "        preds=model.predict(roi)[0]  #Yields one hot encoded result for 7 classes\n",
    "        label=class_labels[preds.argmax()]  #Find the label\n",
    "        label_position=(x,y)\n",
    "        cv2.putText(frame,label,label_position,cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "        \n",
    "   \n",
    "    cv2.imshow('Emotion Detector', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
